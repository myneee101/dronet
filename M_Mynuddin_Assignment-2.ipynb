{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mohammed Mynuddin\n",
    "# ID : 950446781\n",
    "# Subject: Introduction to Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains experiments for:\n",
    "\n",
    "* Loss functions\n",
    "* Learning rate decay\n",
    "* Weight initialization\n",
    "* Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `lincoln` imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lincoln\n",
    "from lincoln.layers import Dense\n",
    "from lincoln.losses import SoftmaxCrossEntropy, MeanSquaredError\n",
    "from lincoln.optimizers import Optimizer, SGD, SGDMomentum\n",
    "from lincoln.activations import Sigmoid, Tanh, Linear, ReLU\n",
    "from lincoln.network import NeuralNetwork\n",
    "from lincoln.train import Trainer\n",
    "from lincoln.utils import mnist\n",
    "from lincoln.utils.np_utils import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz...\n",
      "Downloading t10k-images-idx3-ubyte.gz...\n",
      "Downloading train-labels-idx1-ubyte.gz...\n",
      "Downloading t10k-labels-idx1-ubyte.gz...\n",
      "Download complete.\n",
      "Save complete.\n"
     ]
    }
   ],
   "source": [
    "mnist.init()\n",
    "X_train, y_train, X_test, y_test = mnist.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(y_train)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode\n",
    "num_labels = len(y_train)\n",
    "train_labels = np.zeros((num_labels, 10))\n",
    "for i in range(num_labels):\n",
    "    train_labels[i][y_train[i]] = 1\n",
    "\n",
    "num_labels = len(y_test)\n",
    "test_labels = np.zeros((num_labels, 10))\n",
    "for i in range(num_labels):\n",
    "    test_labels[i][y_test[i]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Demos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale data to mean 0, variance 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train - np.mean(X_train), X_test - np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-33.318421449829934,\n",
       " 221.68157855017006,\n",
       " -33.318421449829934,\n",
       " 221.68157855017006)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(X_train), np.max(X_train), np.min(X_test), np.max(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train / np.std(X_train), X_test / np.std(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.424073894391566, 2.821543345689335, -0.424073894391566, 2.821543345689335)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(X_train), np.max(X_train), np.min(X_test), np.max(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_model(model, test_set):\n",
    "    return print(f'''The model validation accuracy is: {np.equal(np.argmax(model.forward(test_set, inference=True), axis=1), y_test).sum() * 100.0 / test_set.shape[0]:.2f}%''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 \n",
    "# Compare the accuracy of the following neural network architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a). 100 RELU hidden units, 10 Sigmoid output units, MeanSquaredError loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.796\n",
      "Validation loss after 20 epochs is 0.738\n",
      "Validation loss after 30 epochs is 0.721\n",
      "Validation loss after 40 epochs is 0.711\n",
      "Validation loss after 50 epochs is 0.702\n",
      "Validation loss after 60 epochs is 0.698\n",
      "\n",
      "Loss increased after epoch 70, final loss was 0.698, \n",
      "using the model from epoch 60\n",
      "\n",
      "The model validation accuracy is: 38.39%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=100, \n",
    "                  activation=ReLU()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = MeanSquaredError(normalize=False), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 70,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=70);\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss increased after epoch 10, final loss was 1000000000.000, \n",
      "using the model from epoch 0\n",
      "\n",
      "The model validation accuracy is: 9.80%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=100, \n",
    "                  activation=ReLU()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = MeanSquaredError(normalize=True), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 70,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=70);\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model validation accuracy is very low for MeanSquaredError. The reason is that we should be using softmax cross entropy loss!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b). 100 Tanh hidden units, 10 Sigmoid output units, MeanSquaredError loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.602\n",
      "Validation loss after 20 epochs is 0.555\n",
      "Validation loss after 30 epochs is 0.483\n",
      "Validation loss after 40 epochs is 0.461\n",
      "Validation loss after 50 epochs is 0.439\n",
      "Validation loss after 60 epochs is 0.398\n",
      "Validation loss after 70 epochs is 0.383\n",
      "\n",
      "The model validation accuracy is: 71.54%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=100, \n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = MeanSquaredError(normalize=False), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 70,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=70);\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: even if we normalize the outputs of a classification model with mean squared error loss, it still doesn't help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.876\n",
      "\n",
      "Loss increased after epoch 20, final loss was 0.876, \n",
      "using the model from epoch 10\n",
      "The model validation accuracy is: 47.72%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=100, \n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = MeanSquaredError(normalize=True), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 70,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=70);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason is that we should be using softmax cross entropy loss!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c). 100 Sigmoid hidden units, 10 Sigmoid output units, MeanSquaredError loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.654\n",
      "Validation loss after 20 epochs is 0.429\n",
      "Validation loss after 30 epochs is 0.376\n",
      "Validation loss after 40 epochs is 0.356\n",
      "Validation loss after 50 epochs is 0.345\n",
      "Validation loss after 60 epochs is 0.338\n",
      "Validation loss after 70 epochs is 0.332\n",
      "\n",
      "The model validation accuracy is: 73.09%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=100, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = MeanSquaredError(normalize=False), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 70,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=70);\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.582\n",
      "\n",
      "Loss increased after epoch 20, final loss was 0.582, \n",
      "using the model from epoch 10\n",
      "\n",
      "The model validation accuracy is: 62.23%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=100, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = MeanSquaredError(normalize=True), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 70,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=70);\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d). 100 Sigmoid hidden units, 10 Linear output units, Softmax loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 1 epochs is 1.336\n",
      "Validation loss after 2 epochs is 1.015\n",
      "Validation loss after 3 epochs is 0.878\n",
      "Validation loss after 4 epochs is 0.790\n",
      "Validation loss after 5 epochs is 0.741\n",
      "Validation loss after 6 epochs is 0.698\n",
      "Validation loss after 7 epochs is 0.665\n",
      "Validation loss after 8 epochs is 0.645\n",
      "Validation loss after 9 epochs is 0.623\n",
      "Validation loss after 10 epochs is 0.615\n",
      "Validation loss after 11 epochs is 0.595\n",
      "Validation loss after 12 epochs is 0.582\n",
      "Validation loss after 13 epochs is 0.574\n",
      "Validation loss after 14 epochs is 0.563\n",
      "Validation loss after 15 epochs is 0.556\n",
      "Validation loss after 16 epochs is 0.552\n",
      "Validation loss after 17 epochs is 0.539\n",
      "Validation loss after 18 epochs is 0.534\n",
      "Validation loss after 19 epochs is 0.527\n",
      "Validation loss after 20 epochs is 0.518\n",
      "Validation loss after 21 epochs is 0.517\n",
      "Validation loss after 22 epochs is 0.513\n",
      "Validation loss after 23 epochs is 0.505\n",
      "Validation loss after 24 epochs is 0.503\n",
      "Validation loss after 25 epochs is 0.496\n",
      "Validation loss after 26 epochs is 0.494\n",
      "Validation loss after 27 epochs is 0.491\n",
      "Validation loss after 28 epochs is 0.484\n",
      "Validation loss after 29 epochs is 0.482\n",
      "Validation loss after 30 epochs is 0.481\n",
      "Validation loss after 31 epochs is 0.475\n",
      "\n",
      "Loss increased after epoch 32, final loss was 0.475, \n",
      "using the model from epoch 31\n",
      "\n",
      "The model validation accuracy is: 91.34%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=100, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 70,\n",
    "            eval_every = 1,\n",
    "            seed=20190119,\n",
    "            batch_size=70);\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# e). 100 Tanh hidden units, 10 Linear output units, MeanSquaredError loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss increased after epoch 10, final loss was 1000000000.000, \n",
      "using the model from epoch 0\n",
      "\n",
      "The model validation accuracy is: 9.80%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=100, \n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = MeanSquaredError(normalize=False), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 70,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=70);\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 2.006\n",
      "Validation loss after 20 epochs is 1.034\n",
      "\n",
      "Loss increased after epoch 30, final loss was 1.034, \n",
      "using the model from epoch 20\n",
      "\n",
      "The model validation accuracy is: 60.99%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=100, \n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = MeanSquaredError(normalize=True), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 70,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=70);\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 \n",
    "#  Use the best model from the previous question to answer this question. Compare the \n",
    "following SGD momentum algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d is the best model based on the accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Momentum = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 1 epochs is 0.827\n",
      "Validation loss after 2 epochs is 0.656\n",
      "Validation loss after 3 epochs is 0.583\n",
      "Validation loss after 4 epochs is 0.544\n",
      "Validation loss after 5 epochs is 0.526\n",
      "Validation loss after 6 epochs is 0.491\n",
      "Validation loss after 7 epochs is 0.470\n",
      "Validation loss after 8 epochs is 0.461\n",
      "Validation loss after 9 epochs is 0.448\n",
      "Validation loss after 10 epochs is 0.444\n",
      "Validation loss after 11 epochs is 0.430\n",
      "Validation loss after 12 epochs is 0.424\n",
      "\n",
      "Loss increased after epoch 13, final loss was 0.424, \n",
      "using the model from epoch 12\n",
      "The model validation accuracy is: 92.38%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=100, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "optim = SGDMomentum(0.1, momentum=0.7)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(0.1, momentum=0.7))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 70,\n",
    "            eval_every = 1,\n",
    "            seed=20190119,\n",
    "            batch_size=70);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Momentum = 0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 1 epochs is 0.745\n",
      "Validation loss after 2 epochs is 0.589\n",
      "Validation loss after 3 epochs is 0.537\n",
      "Validation loss after 4 epochs is 0.504\n",
      "Validation loss after 5 epochs is 0.489\n",
      "Validation loss after 6 epochs is 0.462\n",
      "Validation loss after 7 epochs is 0.447\n",
      "Validation loss after 8 epochs is 0.431\n",
      "Validation loss after 9 epochs is 0.429\n",
      "Validation loss after 10 epochs is 0.420\n",
      "Validation loss after 11 epochs is 0.411\n",
      "Validation loss after 12 epochs is 0.407\n",
      "\n",
      "Loss increased after epoch 13, final loss was 0.407, \n",
      "using the model from epoch 12\n",
      "The model validation accuracy is: 92.68%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=100, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "optim = SGDMomentum(0.1, momentum=0.8)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(0.1, momentum=0.8))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 70,\n",
    "            eval_every = 1,\n",
    "            seed=20190119,\n",
    "            batch_size=70);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 1 epochs is 0.603\n",
      "Validation loss after 2 epochs is 0.490\n",
      "Validation loss after 3 epochs is 0.449\n",
      "Validation loss after 4 epochs is 0.424\n",
      "Validation loss after 5 epochs is 0.411\n",
      "Validation loss after 6 epochs is 0.392\n",
      "Validation loss after 7 epochs is 0.376\n",
      "Validation loss after 8 epochs is 0.368\n",
      "\n",
      "Loss increased after epoch 9, final loss was 0.368, \n",
      "using the model from epoch 8\n",
      "The model validation accuracy is: 93.53%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=100, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "optim = SGDMomentum(0.1, momentum=0.9)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(0.1, momentum=0.9))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 70,\n",
    "            eval_every = 1,\n",
    "            seed=20190119,\n",
    "            batch_size=70);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3   \n",
    "# Use the best model from the previous question to answer this question. Compare the \n",
    "following weight decay algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a). Linear decay from 0.2 to 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.324\n",
      "\n",
      "Loss increased after epoch 20, final loss was 0.324, \n",
      "using the model from epoch 10\n",
      "The model validation accuracy is: 95.17%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=100, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "optimizer = SGDMomentum(0.2, momentum=0.9, final_lr = 0.02, decay_type='linear')\n",
    "\n",
    "trainer = Trainer(model, optimizer)\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 70,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=70);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b). Exponential decay from 0.25 to 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.322\n",
      "Validation loss after 20 epochs is 0.320\n",
      "\n",
      "Loss increased after epoch 30, final loss was 0.320, \n",
      "using the model from epoch 20\n",
      "The model validation accuracy is: 95.40%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=100, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "optimizer = SGDMomentum(0.25, \n",
    "                        momentum=0.9, \n",
    "                        final_lr = 0.02, \n",
    "                        decay_type='exponential')\n",
    "\n",
    "trainer = Trainer(model, optimizer)\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 70,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=70);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 \n",
    "#  Use the best model from the previous question to answer this question. Compare the \n",
    "Following weight initialization algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a). Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.324\n",
      "\n",
      "Loss increased after epoch 20, final loss was 0.324, \n",
      "using the model from epoch 10\n",
      "The model validation accuracy is: 95.17%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=100, \n",
    "                  activation=Sigmoid(),\n",
    "                  weight_init=\"random\"),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"random\")],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "optimizer = SGDMomentum(0.2, momentum=0.9, final_lr = 0.02, decay_type='linear')\n",
    "\n",
    "trainer = Trainer(model, optimizer)\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "       epochs = 70,\n",
    "       eval_every = 10,\n",
    "       seed=20190119,\n",
    "           batch_size=70,\n",
    "           early_stopping=True);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.322\n",
      "Validation loss after 20 epochs is 0.320\n",
      "\n",
      "Loss increased after epoch 30, final loss was 0.320, \n",
      "using the model from epoch 20\n",
      "The model validation accuracy is: 95.40%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=100, \n",
    "                  activation=Sigmoid(),\n",
    "                  weight_init=\"random\"),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"random\")],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "optimizer = SGDMomentum(0.25, \n",
    "                        momentum=0.9, \n",
    "                        final_lr = 0.02, \n",
    "                        decay_type='exponential')\n",
    "\n",
    "trainer = Trainer(model, optimizer)\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 70,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=70);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b). Glorot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.152\n",
      "\n",
      "Loss increased after epoch 20, final loss was 0.152, \n",
      "using the model from epoch 10\n",
      "The model validation accuracy is: 97.73%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=100, \n",
    "                  activation=Sigmoid(),\n",
    "                  weight_init=\"glorot\"),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"glorot\")],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "optimizer = SGDMomentum(0.2, momentum=0.9, final_lr = 0.02, decay_type='linear')\n",
    "\n",
    "trainer = Trainer(model, optimizer)\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "       epochs = 70,\n",
    "       eval_every = 10,\n",
    "       seed=20190119,\n",
    "           batch_size=70,\n",
    "           early_stopping=True);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.163\n",
      "Validation loss after 20 epochs is 0.162\n",
      "\n",
      "Loss increased after epoch 30, final loss was 0.162, \n",
      "using the model from epoch 20\n",
      "The model validation accuracy is: 97.62%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=100, \n",
    "                  activation=Sigmoid(),\n",
    "                  weight_init=\"glorot\"),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"glorot\")],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "optimizer = SGDMomentum(0.25, \n",
    "                        momentum=0.9, \n",
    "                        final_lr = 0.02, \n",
    "                        decay_type='exponential')\n",
    "\n",
    "trainer = Trainer(model, optimizer)\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 70,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=70);\n",
    "\n",
    "calc_accuracy_model(model, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
